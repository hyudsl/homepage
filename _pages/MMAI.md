---
layout: interests-post
title: Multi-modal AI
permalink: '/MMAI.html'
---

# Data Science Lab's Natural Language Processing (NLP) Research

## Introduction to Multimodal Information Processing
Multimodal Information Processing은 텍스트, 음성, 영상 등 다양한 데이터 유형을 결합하여 보다 정교하고 유용한 정보를 생성하거나 활용하는 기술입니다. 이러한 기술은 자동 음성 인식(ASR), 멀티모달 번역, 실시간 대화형 시스템과 같은 응용 분야에서 중요한 역할을 합니다. 데이터 사이언스 연구실에서는 멀티모달 데이터를 통합하여 복잡한 문제를 해결하고, 사용자가 보다 자연스럽게 시스템과 상호작용할 수 있도록 돕는 연구를 진행하고 있습니다.

** 대표적인 멀티모달 연구 주제 **

- 멀티모달 데이터 통합: 텍스트, 음성, 영상 데이터를 결합하여 종합적인 의사결정을 지원합니다.
- Vision-Language Agent: 텍스트와 영상 데이터를 기반으로 상황을 이해하고 실시간으로 적절한 결정을 내리는 시스템을 개발합니다.

다음은 연구실에서 진행한 Multimodal Information Processing 연구의 구체적인 내용입니다.

## Improving Domain-Specific Automatic Speech Recognition (ASR)
도메인 특화 자동 음성 인식은 특정 산업 및 전문 분야의 음성을 더 정확하게 인식하는 데 필수적입니다. 연구실은 LLM 기반 컨텍스트 설명 생성 기법을 도입하여 ASR 모델의 성능을 향상시키는 방법론을 개발했습니다. 이를 통해 다양한 도메인에서 높은 인식률을 제공하며, 의료, 법률, 금융 등의 분야에서 활용 가능합니다.

* Jiwon Suh, Injae Na, Woohwan Jung, "Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions", ([Interspeech 2024]https://www.isca-archive.org/interspeech_2024/suh24_interspeech.html/)

## Join Us
데이터 사이언스 연구실은 AI와 NLP 분야의 최첨단 기술로 실제 문제를 해결하고자 하는 열정적인 연구자를 찾고 있습니다. 관심이 있으시다면 [Contact Us](https://dsl.hanyang.ac.kr/contact)를 통해 연락해 주세요.
